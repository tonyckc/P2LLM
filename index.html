<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Large Language Models for Lossless Image Compression: Next-Pixel Prediction in Language Space is All You Need">
  <meta name="keywords" content="Large Language Models, Lossless Image Compression, Next-Pixel Prediction">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Large Language Models for Lossless Image Compression: Next-Pixel Prediction in Language Space is All You Need</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="./static/js/video_comparison.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://tonyckc.github.io/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://github.com/tonyckc/P2LLM/">
            Large Language Models for Lossless Image Compression
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Large Language Models for Lossless Image Compression: Next-Pixel Prediction in Language Space is All You Need<br>
            <small>
              <span style="font-size: 60%;">NeurIPS 2025</span>
            </small>
          </h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://tonyckc.github.io/">Kecheng Chen</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://pingpingzhang.com/">Pingping Zhang</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://scholars.cityu.edu.hk/en/persons/liuhui3/">Hui Liu</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://scholars.cityu.edu.hk/en/persons/jliu288/">Jie Liu</a><sup>1</sup>,</span>
            <span class="author-block">
              <a>Yibing Liu</a><sup>2</sup>,</span>
            <span class="author-block">
              <a>Jiaxin Huang</a><sup>3</sup>,</span>
            <span class="author-block">
              <a href="https://www.cs.cityu.edu.hk/~shiqwang/">Shiqi Wang</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://www.ee.cityu.edu.hk/~hpyan/">Hong Yan</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://hlli1991.github.io/">Haoliang Li</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup> Department of Electrical Engineering and the CIMDA, City University of Hong Kong</span><br>
            <span class="author-block"><sup>2</sup> Department of Computer Science, City University of Hong Kong</span><br>
            <span class="author-block"><sup>3</sup> Mohamed bin Zayed University of Artificial Intelligence</span><br>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2411.12448"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!--/ PDF Link. -->
              <!-- Code Link. -->
              <span class="tooltip">
              <span class="link-block">
                <a href="https://github.com/tonyckc/P2-LLM"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!--/ Code Link. -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Figure_1. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div style="text-align: center;">
          <img src="assets/framework-p2llm.png" alt="Figure 1"  width="100%"/>
        </div>
      </div>
    </div>
    <!--/ Figure_1. -->
    
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We have recently witnessed that "Intelligence" and "Compression" are the two sides of the same coin, where the language large model (LLM) with unprecedented intelligence is a general-purpose lossless compressor for various data modalities. This attribute particularly appeals to the lossless image compression community, given the increasing need to compress high-resolution images in the current streaming media era. Consequently, a spontaneous envision emerges: Can the compression performance of the LLM elevate lossless image compression to new heights? However, our findings indicate that the naive application of LLM-based lossless image compressors suffers from a considerable performance gap compared with existing state-of-the-art (SOTA) codecs on common benchmark datasets. In light of this, we are dedicated to fulfilling the unprecedented intelligence (compression) capacity of the LLM for lossless image compression tasks, thereby bridging the gap between theoretical and practical compression performance. Specifically, we propose P²-LLM, a next-pixel prediction-based LLM, which integrates various elaborated insights and methodologies, e.g., pixel-level priors, the in-context ability of LLM, and a pixel-level semantic preservation strategy, to enhance the understanding capacity of pixel sequences for better next-pixel predictions. Extensive experiments on benchmark datasets demonstrate that P²-LLM can beat SOTA classical and learned codecs.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <div class="column is-centered has-text-centered">
      <h2 class="title is-3">Performance Comparison</h2>
    </div>
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <section class="hero is-light is-small">
          <div class="hero-body">
            <div class="container">
                <div style="text-align: center;">
                  <img src="assets/performance-p2llm.png" alt="Figure 2"  width="100%"/>
                </div>
                <div class="content has-text-justified">
                  <p> Comparison of different lossless image compressors for bit-per-subpixel (bpsp↓) on CLIC.m dataset. Classical compressors include PNG, WebP, FLIF, and JPEG-XL. P²-LLM achieves 2.08 bpsp, outperforming SOTA classical and learned codecs. </p>
                </div>
            </div>
          </div>
        </section>
      </div>
    </div>
    <!--/ Paper video. -->

  </div>
</section>




<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{chen2025p2llm,
  title={Large Language Models for Lossless Image Compression: Next-Pixel Prediction in Language Space is All You Need},
  author={Kecheng Chen and Pingping Zhang and Hui Liu and Jie Liu and Yibing Liu and Jiaxin Huang and Shiqi Wang and Hong Yan and Haoliang Li},
  journal={NeurIPS},
  year={2025}
}</code></pre>
  </div>
</section>
<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=rhBYF1NVAJSwRuDj6gegOAQodKeBZljSttYXlL4GWcc&cl=ffffff&w=a"></script>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/tonyckc/P2-LLM">source code</a> of this website,
            we just ask that you link back to this page in the footer. Some of the source code of this 
            website is borrowed from <a href="https://nerfies.github.io">nerfies</a> and <a href="https://dorverbin.github.io/refnerf/">Ref-NeRF</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
